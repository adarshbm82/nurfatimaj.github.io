[{"authors":["admin"],"categories":null,"content":"Welcome!\nI am currently a post-doctoral associate at the University of Minnesota. I earned the PhD in Economics in 2021 from the European University Institute under the supervision of Prof. Andrea Ichino and Prof. Giacomo Calzolari.\nMy area of expertise is Applied Microeconomics. My thesis \u0026ldquo;Essays in Applied Microeconomics\u0026rdquo; includes four chapters mainly focusing on the interaction between intelligence and individual choices in education, labour market and fertility. I am interested in topics related to determinants of educational choices and career path, as well as using genetic data in economics research.\n","date":1632225600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1632225600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Welcome!\nI am currently a post-doctoral associate at the University of Minnesota. I earned the PhD in Economics in 2021 from the European University Institute under the supervision of Prof. Andrea Ichino and Prof.","tags":null,"title":"Nurfatima Jandarova","type":"authors"},{"authors":["arustichini"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e3825803958bcee7c7eaaa92750cb108","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Aldo Rustichini","type":"authors"},{"authors":["aichino"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"781e653cbbcf07ee9e996d12c5ae4bd3","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Andrea Ichino","type":"authors"},{"authors":["gzanella"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"df1e9faf8af7b263dc3477a583303413","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Giulio Zanella","type":"authors"},{"authors":["hkase"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"eb5bcd6578baef7f63b913414391ea09","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Hanno Kase","type":"authors"},{"authors":["jlreuter"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6655caf5f630fc025a067b6ec176656c","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Johanna Reuter","type":"authors"},{"authors":["ldimbou"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f35ba751f509162e367cd98021008b7","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Loic Yengo","type":"authors"},{"authors":["mboldrin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"91eefaa0dc0c6c0585797ce4d2ca7d4e","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Michele Boldrin","type":"authors"},{"authors":["pvisccher"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c9e2abd5fafe679711a8f5987d8c2b2a","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Peter Visscher","type":"authors"},{"authors":["Nurfatima Jandarova"],"categories":null,"content":"You can register to attend at the EUI website.\n","date":1632225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632225600,"objectID":"e55610623473b04680789038efc0eeb0","permalink":"https://nurfatimaj.com/talk/essays-in-applied-microeconomics/","publishdate":"2021-09-14T23:14:58+06:00","relpermalink":"/talk/essays-in-applied-microeconomics/","section":"event","summary":"PhD Thesis Defence","tags":null,"title":"Essays in Applied Microeconomics","type":"event"},{"authors":null,"categories":["tech fun"],"content":"It all started with my supervisor filling in a data request form for the joint project and \u0026ldquo;complaining\u0026rdquo; that his RAs still don\u0026rsquo;t have their websites. I thought that I\u0026rsquo;d need one in a year\u0026rsquo;s time anyway, so why not do it now?\nMaybe you can guess from the previous post, but I am a person who just doesn\u0026rsquo;t like unnecessarily duplicating work. Therefore, I wanted my website generate my CV document since they share most of the information.\nAt this point, you probably think that I have too much time to waste. You are probably right. But I had already started this journey and I needed to bring it to a satisfactory finish. And I also like to think that it benefits future me by freeing up a little bit of time each year from needing to update profile twice.\nThe general idea is simple: to have all my CV entries in a kind of database and let the algorithms put them both to website and CV document. We are living in an age of artificial intelligence after all. Should be easy peasy!\nWordPress My first attempt was WordPress because of rich functionality. In particular, it already has some special CV plugins that save my information into a specific database and build CV pages using this database. However, making it output same information into a beautiful pdf has proven to be very difficult to do using open source solutions. In a hindsight, I must say that WordPress is also an overkill for such a simple personal page project.\nHugo Luckily, my boyfriend knows a lot of things and has introduced me to the world of Hugo. It is a simple, free, static-site generator with the support of data-driven content. The financial benefit of Hugo is that I can host it for free on GitHub; thus, only paying for a custom domain name. Personally, it feels that comparing Hugo to WordPress is like comparing LaTeX to Word.\nWhile, it may be less user-friendly than WordPress, it would have only taken me couple of hours to have my site up and running. However, I needed a functionality not offered by ready-to-use themes. So, I needed some tweaking.\nhugo-resume First, I was working with hugo-resume theme. It had the most important feature I needed: data-driven content.\nBut how do I get my CV as a pdf file? I had an idea. I could generate a second page that looks exactly like I want my CV document to look and simply print it to pdf in the browser. To make it a bit more explicit, I have also included a button in the home page that opens the printer dialogue attempting to print the CV page. All print dialogues should have \u0026lsquo;Save as PDF\u0026rsquo; option.\nIt worked, but it wasn\u0026rsquo;t a perfect solution.\n Showing a print window with a possible choice of saving a file as pdf is making too many suppositions on behalf of the user. I would still prefer having a link to a pdf file. I have made so many tweaks to the theme that it basically became a completely new theme. Which meant that there are many places, where a potential bug could be sitting. Which meant maintenance would require quite a bit of my time. Related to the previous one, I did not like the visual appeal of the original theme and had to add style changes as well. This of course increases probability of having a buggy code.  hugo-academic It is porbably the most popular theme on Hugo. And you can tell it from the rigour of the theme\u0026rsquo;s documentation. The developers have thought about many features. Except for the possibility of sending the website data into a beautiful pdf.\nTweaking this website is easy and difficult at the same time.\n Why is it difficult? Precisely because of its flexbility, the structure of the theme is not the easiest to understand. So, even if I knew exactly what I want to tweak, it took me some time to understand where should I apply those tweaks. Beyond beginner knowledge of Hugo is required. Why is it easy? Because the files are organized into nice small chunks divided by functionality and there is a very good documentation with a step-by-step guide of creating your own \u0026ldquo;widget\u0026rdquo;. Unlike the previous theme, this one has been adapted to allow different user tastes for looks. I only needed to add a bit of code that converts CV to pdf file.  After having had some experience with Hugo templating, creating a new page with information for CV did not take much time. But how do I get a link to a pdf file instead of getting a print dialogue? Initially, I thought of printing to pdf before sending the data to the webpage. That is, I build website on my computer, send the generated page to printer, save it as pdf, add the link to this pdf on the home and send the website to GitHub. To automate this process, I used chrome command line interface, the worst solution I have tried (except for the idea of two separate files). The thing with chrome CLI is that it doesn\u0026rsquo;t work properly with chrome running in the background (and even without). The resulting pdf file always had different levels of white overlay.\nI was very unhappy about this. And was thinking \u0026ldquo;Oh, if only there was a way to let LaTeX generate this poor pdf!\u0026rdquo;. But the problem with this is that I don\u0026rsquo;t know how to access website information from within LaTeX.\nThe solution came to me the same way as the chemical table came to Mendeleev - in the dream. The idea - and current solution - is to have an auxiliary html page for CV with LaTeX code. For example, instead of \u0026lt;h2\u0026gt;Contact Information\u0026lt;/h2\u0026gt; for section names I put \\section*{Contact Information} into the template. Then, I run Python script to extract the LaTeX codes and supply them to pdflatex to generate a good-looking pdf. This is the best solution as it allows me\n to have my CV information in one place that fuels both webpage and CV document, and to control the look of CV document via latex commands.  Final words I surely hope that this is the end of this saga and I will not have another crazy idea to add to the CV ðŸ˜… Apart from that, I feel this is the ideal solution to my initial request!\n","date":1571586300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571586300,"objectID":"e9bd2643a471e82b350887986ad4745d","permalink":"https://nurfatimaj.com/post/tech-fun/personal-page-quest/","publishdate":"2019-10-20T17:45:00+02:00","relpermalink":"/post/tech-fun/personal-page-quest/","section":"post","summary":"It all started with my supervisor filling in a data request form for the joint project and \u0026ldquo;complaining\u0026rdquo; that his RAs still don\u0026rsquo;t have their websites. I thought that I\u0026rsquo;d need one in a year\u0026rsquo;s time anyway, so why not do it now?\n","tags":["data-driven website","automatic CV","Hugo","latex"],"title":"[Not] easy personal website","type":"post"},{"authors":null,"categories":["tech fun"],"content":"At the beginning of PhD I used to have at most one project at a time. Keeping track of things was easy. Along the way, I accumulated a portfolio of projects. For each of them I write tons of codes (partly because my programmer sister has taught me that having one big file with everything is bad). One day I found myself looking at my own code of three months earlier and spending half a day to retrace its logic. There were dozens of errors before I was able to run everything smoothly without forgetting some annoying little detail.\nThen it became clear to me that I need to keep a proper documentation. Hopefully, it is also helpful when one day the papers get published. Be it couple of files, I could have done it all manually. Or maybe not\u0026hellip; Just the thought that I would need to keep track of twice as many documents sends me to shiver. Search for some ready solution did not yield much results: either my target programming languages are too \u0026ldquo;simple\u0026rdquo;, or the output is not what I was looking for.\nAfter a little thinking it struck me that automatic documentation is nothing more than a text parsing exercise. So I set out to write my own script. It searches for all new or recently modified code files in my project folder, parses the text and pastes it to a markdown file in my documentation subfolder. In this project I rely a lot on git version control and remote repository that keeps all important code files.\nTechnical bits Code structure The benefit of having an automatic documentation generation script is that I can keep all documentation-relevant information inside the code file. Then keeping documentation up-to-date is only a matter of updating comments inside the code file.\nSpecial comment Not all comments are meant to be inside a documentation file. Detecting the relevant code blocks is solved by including a special comment block (#' or *' for Stata) which I have borrowed from R. So all lines that start with the special sign will be part of the documentation file.\nParsing and outputing After detecting the special comment block, the script is ridiculously simple. Basic idea is to strip away the special comment sign and simply copy the rest of the text into a markdown file. Of course, for this to work, the documentation comment block should follow a simple markdown syntax.\nMy documentation script applies additional rules to certain lines, which, again borrowing from R, are identified with special tags (for example, @title for document title). These rules work by identifying if a line starts with one of the special tags, stripping the tag away and outputing the rest of the text in a desired way. For example, when a line starts with @title, I insert to the title text hyperlink to the actual code file. The linking is possible because I am using git version control with a remote repository.\nTo a more technically inclined reader, all that my script does here is continuously apply sed to the extracted lines and echo the output into a markdown file.\nInput The script works both with single code file and with a project folder that contains the code files. That is, it is really easy to mass generate documentation files.\nHowever, not all the codes in the folder need documentation; for example, a script from workshop I use as a reference. My script relies on git version control in deciding which files are relevant: if it is controlled by git, then it is worth a documentation.\nPublishing Since I am using git and remote repository, I am also using wiki submodule to publish the documentation files. While GitHub requires public repository for wiki functionality to work, Bitbucket allows it on private repositories too. The path to the documentation files inside wiki follows is similar to the code file path inside project directory.\nIf I have time in the future, \u0026hellip; \u0026hellip; I would like to make the script a bit more flexible. Currently, my script parses and outputs documentation information line by line. Therefore, it can neither reorder sections nor augment with information found later under the same section heading. The output will look exactly the same way as the comment block. So, a nice extension would have been to extract all section-relevant data into a separate array and then output everything together. This would allow special comments organized like this\n#' @section1 #' comment 1 #' #' @section2 #' comment 1 #' #' @section1 #' comment 2  to appear correctly in the documentation file: two comments under section 1 and one comment under section 2.\nSummary Now, I can just click on respective wiki post and see all relevant information: usage, argument types and accepted values, description, input and output files. No need to traverse the code to make sense of it. Just work on the actual task.\n","date":1566038022,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566038022,"objectID":"1c238270ce3f9bd77542190e87b2151b","permalink":"https://nurfatimaj.com/post/tech-fun/automatic-documentation/","publishdate":"2019-08-22T20:00:00+06:00","relpermalink":"/post/tech-fun/automatic-documentation/","section":"post","summary":"At the beginning of PhD I used to have at most one project at a time. Keeping track of things was easy. Along the way, I accumulated a portfolio of projects. For each of them I write tons of codes (partly because my programmer sister has taught me that having one big file with everything is bad). One day I found myself looking at my own code of three months earlier and spending half a day to retrace its logic. There were dozens of errors before I was able to run everything smoothly without forgetting some annoying little detail.\n","tags":["software","documentation","git","bash script","markdown","text parsing"],"title":"Automatic documentation","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"07e82b29ab4ada67b89956e1eb6ed8e1","permalink":"https://nurfatimaj.com/print/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/print/","section":"","summary":"","tags":null,"title":"CV","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://nurfatimaj.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":["Nurfatima Jandarova"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5827b4f834a1a051b00681aead9d6a02","permalink":"https://nurfatimaj.com/publication/work-in-progress/unemp-parent-intel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/work-in-progress/unemp-parent-intel/","section":"publication","summary":"The negative effect of parental job loss on various outcomes of children is well-documented. In this paper, I provide new evidence on the heterogeneity of these effects along the cognitive ability distribution of children. I find that higher intelligence score protects children from the negative effects, but only in the long run. In the shorter term, instead of protecting, high ability exacerbates the cost of parental unemployment in terms of educational outcomes. This forces high-ability children with unemployed parents to start their careers at lower-paying jobs. Nevertheless, they can prove themselves via work performance and switch to better-paying jobs. I also provide suggestive evidence that their lifetime earnings could be higher had they continued their education.","tags":["work in progress"],"title":"Does intelligence shield from negative family shocks?","type":"publication"},{"authors":["Nurfatima Jandarova","Michele Boldrin","Aldo Rustichini"],"categories":[],"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"14e81f975260d0a055c7095f556f7d4b","permalink":"https://nurfatimaj.com/publication/work-in-progress/fertility_iq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/work-in-progress/fertility_iq/","section":"publication","summary":"","tags":["work in progress"],"title":"Fertility Choice and Intelligence in Developed Countries","type":"publication"},{"authors":["Nurfatima Jandarova"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9f3d7c482106eb3cde45e59a649a4593","permalink":"https://nurfatimaj.com/publication/work-in-progress/edu-unemp/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/work-in-progress/edu-unemp/","section":"publication","summary":"There is growing evidence on the \"scarring\" effects of entering the labour market during a recession, especially among less-educated workers. However, the existing literature has treated educational attainment as a pre-determined characteristic. In this paper, I study the effect of local economic conditions on educational decisions and subsequent labour market outcomes using the instrumental variable approach. First, I find that adverse economic conditions at age 14 reduce educational attainment, except for the children aiming at university degrees. Second, exposure to a higher unemployment rate at age 14 permanently reduces real hourly wages over the life cycle. The IV estimator suggests that a year of education lost due to initial economic conditions corresponds to about 8% lower wages at ages 26-30 and 6% lower wages at ages 41-45.","tags":["work in progress"],"title":"From bad to worse: long-term effects of recession in adolescence","type":"publication"},{"authors":["Andrea Ichino","Nurfatima Jandarova","Johanna Reuter","Aldo Rustichini","Peter Visscher","Loic Yengo","Giulio Zanella"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fbb19ba8c7a5b3a393e17e7acbd162dd","permalink":"https://nurfatimaj.com/publication/work-in-progress/uni-sorting-genetics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/work-in-progress/uni-sorting-genetics/","section":"publication","summary":"","tags":["work in progress"],"title":"Intelligence and Tertiary Education","type":"publication"},{"authors":["Nurfatima Jandarova","Johanna Reuter"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c9f1edf3f4668f9d50ace3cc8720462c","permalink":"https://nurfatimaj.com/publication/work-in-progress/mi-uni/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/work-in-progress/mi-uni/","section":"publication","summary":"Historically higher education in the UK has been shaped by a dual system: elite universities on the one hand and polytechnics and other higher education institutions on the other. Despite the for- mal equivalence of both degrees, the two institution types faced different financing, target populations, admission procedures and subjects taught. Nevertheless, in survey data they are often indis- tinguishable. In this paper, we differentiate the institution types among degree-holders using a multiple imputation technique in the UKHLS and BHPS datasets. We examine the validity of inference based on imputed values using Monte Carlo simulations. We also verify that the imputed values are consistent with university graduation rates computed using the universe of undergraduate students in the UK.","tags":["work in progress"],"title":"Multiple Imputation of University Degree Attainment","type":"publication"},{"authors":null,"categories":null,"content":"This website uses cookies to gather analytical information processed by the Google Analytics 4. The analytical information concerns page views only. As part of the report, I can see aggregated statistics about\n name of pages visited, country from where pages were visited, whether a visit came from external links, or by directly typing the address.  The cookie consent is opt-in type. This means that all of the above information is only collected, if a user has specifically given consent for data collection.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://nurfatimaj.com/privacy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/privacy/","section":"","summary":"This website uses cookies to gather analytical information processed by the Google Analytics 4. The analytical information concerns page views only. As part of the report, I can see aggregated statistics about","tags":null,"title":"Privacy","type":"page"}]